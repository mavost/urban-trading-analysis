{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to play with ATRs\n",
    "\n",
    "Latest version: 2024-08-23  \n",
    "Author: MvS\n",
    "\n",
    "## Description\n",
    "\n",
    "Notebook to illustrate and calculate the average true range (ATR) indicator:\n",
    "\n",
    "- measure volatility of equity prices, including gaps between trading periods\n",
    "\n",
    "\n",
    "## Result\n",
    "\n",
    "It has multiple [uses](https://skilltrader.de/average-true-range-strategien/):\n",
    "\n",
    "- dynamic stop-loss calculation,\n",
    "- breakout signal,\n",
    "- pullback strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "from math import log2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standard SMAs\n",
    "periods = [200, 50]\n",
    "\n",
    "# stock = \"FROG\"\n",
    "# stock = \"TSLA\"\n",
    "# stock = \"NVDA\"\n",
    "# stock = \"SAP.TO\"\n",
    "# stock = \"GLEN.L\"\n",
    "stock = \"ADM.L\"\n",
    "# stock = \"SPX.L\"\n",
    "# stock = \"JPM\"\n",
    "\n",
    "dt_end = datetime.datetime.today()\n",
    "# Define real-time interval:\n",
    "#  - assume to display at least the number of sample points of the larger period\n",
    "#  - this requires double the number of points to create the averaging\n",
    "#  - plus considering non-trading days - yfinance returns only trading days, howevers\n",
    "dt_data_start = dt_end - datetime.timedelta(days=max(periods) * 3)\n",
    "\n",
    "try:\n",
    "    # Grab sufficient stock data for averaging SMAs\n",
    "    load_df = yf.download(\n",
    "        f\"{stock}\",\n",
    "        start=dt_data_start.strftime('%Y-%m-%d'),\n",
    "        end=dt_end.strftime('%Y-%m-%d'),\n",
    "        progress=False,\n",
    "    )\n",
    "\n",
    "    assert load_df.shape[1] == 6 and load_df.shape[0] > max(periods)\n",
    "\n",
    "except AssertionError:\n",
    "    print(f\"Download failed for symbol {stock}.  Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiton and calculation of ATR indicator\n",
    "\n",
    "Source: [Investopedia](https://www.investopedia.com/terms/a/atr.asp)\n",
    "\n",
    "1. True range is defined as `TR = Max[(H−L), ∣H−Cp​∣, ∣L−Cp​∣]` where:\n",
    "\n",
    "    - `H`: Today’s high\n",
    "    - `L`: Today’s low\n",
    "    - `Cp`: Yesterday’s closing price\n",
    "    - `Max`: Highest value of the three terms\n",
    "\n",
    "2. ATR is the arithmetic mean of the daily true ranges over previous periods\n",
    "\n",
    "3. Added a low-end volatility estimate which I define as `LR = Max[((Cp+H)/2.0) - L, (Cp - L)]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we calculated the SMAs and EMAs, we can remove the data points before the actual AOI that we want.\n",
    "stock_df = load_df[-max(periods) :].copy()\n",
    "\n",
    "\n",
    "# calculate true range\n",
    "def true_range(x):\n",
    "    high = x['High']\n",
    "    low = x['Low']\n",
    "    close_p = x['ClosePrev']\n",
    "\n",
    "    if pd.isna(close_p):\n",
    "        return high - low\n",
    "    else:\n",
    "        return max(\n",
    "            high - low,\n",
    "            abs(high - close_p),\n",
    "            abs(close_p - low),\n",
    "        )\n",
    "\n",
    "\n",
    "stock_df['ClosePrev'] = stock_df['Close'].shift(1)\n",
    "\n",
    "\n",
    "# calculate low range\n",
    "def low_range(x):\n",
    "    open = x['Open']\n",
    "    high = x['High']\n",
    "    low = x['Low']\n",
    "    close_p = x['ClosePrev']\n",
    "\n",
    "    if pd.isna(close_p):\n",
    "        return (open + high) / 2.0 - low\n",
    "    else:\n",
    "        return max((close_p + high) / 2.0 - low, close_p - low, 0)\n",
    "\n",
    "\n",
    "# calculate high range\n",
    "def high_range(x):\n",
    "    open = x['Open']\n",
    "    high = x['High']\n",
    "    low = x['Low']\n",
    "    close_p = x['ClosePrev']\n",
    "\n",
    "    if pd.isna(close_p):\n",
    "        return high - (open + low) / 2.0\n",
    "    else:\n",
    "        return max(high - (close_p + low) / 2.0, high - close_p, 0)\n",
    "\n",
    "\n",
    "stock_df['ClosePrev'] = stock_df['Close'].shift(1)\n",
    "\n",
    "stock_df['TR'] = stock_df.apply(true_range, axis=1)\n",
    "stock_df['LR'] = stock_df.apply(low_range, axis=1)\n",
    "stock_df['HR'] = stock_df.apply(high_range, axis=1)\n",
    "\n",
    "# Define the columns and their styles\n",
    "columns = [\n",
    "    'High',\n",
    "    'Low',\n",
    "    'Close',\n",
    "    'ClosePrev',\n",
    "    'TR',\n",
    "]\n",
    "colors = ['darkgreen', 'red', 'forestgreen', 'orangered', 'grey']\n",
    "linestyles = ['-', '-', ':', ':', '-']\n",
    "\n",
    "# Plot each column separately\n",
    "ax = None\n",
    "for col, color, style in zip(columns, colors, linestyles):\n",
    "    ax = stock_df[col].plot(color=color, linestyle=style, ax=ax)\n",
    "\n",
    "\n",
    "# clean up\n",
    "stock_df.drop(\n",
    "    ['ClosePrev'],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    "    errors='ignore',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a subplot with secondary y-axis enabled\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add the candlestick chart\n",
    "fig.add_trace(\n",
    "    go.Candlestick(\n",
    "        x=stock_df.index,\n",
    "        open=stock_df['Open'],\n",
    "        high=stock_df['High'],\n",
    "        low=stock_df['Low'],\n",
    "        close=stock_df['Close'],\n",
    "        name=f\"{stock}\",\n",
    "    ),\n",
    "    secondary_y=False,  # Assign to the primary y-axis\n",
    ")\n",
    "\n",
    "# Add the scatter plot for negative volatility\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=stock_df.index,\n",
    "        y=stock_df[f\"LR\"],\n",
    "        mode='lines',\n",
    "        name=f\"Negative volatility\",\n",
    "        line=dict(color='#FF5252', width=2, dash='dot'),\n",
    "    ),\n",
    "    secondary_y=True,  # Assign to the secondary y-axis\n",
    ")\n",
    "\n",
    "# Update y-axes to use a logarithmic scale (optional)\n",
    "fig.update_yaxes(type='log', secondary_y=False)  # Log scale for primary y-axis\n",
    "fig.update_yaxes(title_text=\"Negative Volatility\", secondary_y=True)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Standard candlesticks and trading signals based on EMAs',\n",
    "    yaxis_title=f\"{stock} Stock\",\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify extrema: full ATR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = int(len(stock_df) * 0.05)\n",
    "\n",
    "# Your original plot\n",
    "ax = stock_df['TR'].plot(label='ATR', linestyle='-')\n",
    "\n",
    "# Get the indices of the top 10 values in 'TR'\n",
    "markers_on = stock_df['TR'].sort_values(ascending=False)[:outliers]\n",
    "\n",
    "label = f'top {outliers} extrema'\n",
    "\n",
    "# Loop over the selected indices and plot markers\n",
    "for index in markers_on.index:\n",
    "    ax.plot(index, stock_df['TR'].loc[index], 'oy', mfc='none', label=label)\n",
    "    label = None\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify extrema: negative range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = int(len(stock_df) * 0.05)\n",
    "\n",
    "# Your original plot\n",
    "ax = stock_df['LR'].plot(label='line', linestyle='-')\n",
    "\n",
    "# Get the indices of the top 10 values in 'TR'\n",
    "markers_series = stock_df['LR'].sort_values(ascending=False)[:outliers]\n",
    "\n",
    "label = f'top {outliers} extrema'\n",
    "\n",
    "# Loop over the selected indices and plot markers\n",
    "for index in markers_series.index:\n",
    "    ax.plot(index, stock_df['LR'].loc[index], 'oy', mfc='none', label=label)\n",
    "    label = None\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify extrema: positive range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = int(len(stock_df) * 0.05)\n",
    "\n",
    "# Your original plot\n",
    "ax = stock_df['HR'].plot(label='line', linestyle='-')\n",
    "\n",
    "# Get the indices of the top 10 values in 'TR'\n",
    "markers_series = stock_df['HR'].sort_values(ascending=False)[:outliers]\n",
    "\n",
    "label = f'top {outliers} extrema'\n",
    "\n",
    "# Loop over the selected indices and plot markers\n",
    "for index in markers_series.index:\n",
    "    ax.plot(index, stock_df['HR'].loc[index], 'oy', mfc='none', label=label)\n",
    "    label = None\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract isolated maxima from series\n",
    "\n",
    "To get an estimate for the strongest daily movement in a turbulent trading phase\n",
    "\n",
    "Note, that this extremum and neigboring suppressed extrema can accumulate to much larger numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_isolated_spikes(series, num_spikes=10, n_distance=5):\n",
    "    \"\"\"\n",
    "    Find isolated maximum spikes in a Pandas series with a safety distance between each event.\n",
    "\n",
    "    :param series: Input Pandas Series.\n",
    "    :param num_spikes: Number of spikes to identify.\n",
    "    :param n_distance: Safety distance between each identified spike.\n",
    "    :return: DataFrame with the positions and values of the identified spikes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the series to avoid modifying the original\n",
    "    series_copy = series.copy()\n",
    "\n",
    "    # List to hold the positions and values of the identified spikes\n",
    "    spikes = []\n",
    "\n",
    "    distance = n_distance * datetime.timedelta(days=1)\n",
    "\n",
    "    max_seridx = max(series.index)\n",
    "    min_seridx = min(series.index)\n",
    "\n",
    "    for _ in range(num_spikes):\n",
    "        # Find the index of the maximum value in the series\n",
    "        max_idx = series_copy.idxmax()\n",
    "        max_value = series_copy[max_idx]\n",
    "        # print(f\"{num_spikes}: {max_idx} {max_value}\")\n",
    "\n",
    "        # Save the maximum spike (index and value)\n",
    "        spikes.append((max_idx, max_value))\n",
    "\n",
    "        # Suppress the values around the maximum spike\n",
    "        start_idx = max(min_seridx, max_idx - distance)\n",
    "        end_idx = min(max_seridx, max_idx + distance)\n",
    "\n",
    "        series_copy[start_idx:end_idx] = np.nan\n",
    "\n",
    "    # Convert the result to a DataFrame for better readability\n",
    "    spikes = list(zip(*spikes))\n",
    "    series = pd.Series(spikes[1], index=spikes[0])\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "high_markers_series = find_isolated_spikes(stock_df['HR'], num_spikes=10, n_distance=5)\n",
    "low_markers_series = find_isolated_spikes(stock_df['LR'], num_spikes=10, n_distance=5)\n",
    "\n",
    "# Merge series to df\n",
    "extrema_df = pd.concat(\n",
    "    [high_markers_series, low_markers_series], axis=1, keys=['HR', 'LR']\n",
    ")\n",
    "extrema_df.sort_index(ascending=True, axis=0, inplace=True)\n",
    "\n",
    "# Plot extrema\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# Your original plot\n",
    "ax_hr = stock_df['HR'].plot(ax=axes[0], label='HR line', linestyle='-')\n",
    "ax_lr = stock_df['LR'].plot(ax=axes[1], label='LR line', linestyle='-')\n",
    "\n",
    "label = f'top {outliers} iso-extrema'\n",
    "\n",
    "# Loop over the selected indices and plot markers\n",
    "for index in extrema_df[~extrema_df['HR'].isna()].index:\n",
    "    ax_hr.plot(index, stock_df['HR'].loc[index], 'oy', mfc='none', label=label)\n",
    "    label = None\n",
    "\n",
    "label = f'top {outliers} iso-extrema'\n",
    "for index in extrema_df[~extrema_df['LR'].isna()].index:\n",
    "    ax_lr.plot(index, stock_df['LR'].loc[index], 'oy', mfc='none', label=label)\n",
    "    label = None\n",
    "\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(8)\n",
    "ax_hr.legend(loc=\"upper left\")\n",
    "ax_lr.legend(loc=\"upper left\")\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.legend()\n",
    "plt.show()\n",
    "\n",
    "del high_markers_series, low_markers_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate different averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##---- Different means\n",
    "scaler = 1.0\n",
    "\n",
    "# Take valid extrema\n",
    "for item in ['HR', 'LR']:\n",
    "    markers_series = extrema_df[~extrema_df[item].isna()][item]\n",
    "\n",
    "    arithmetic_mean = markers_series.sum() / len(markers_series) * scaler\n",
    "    harmonic_mean = len(markers_series) / (1 / markers_series).sum() * scaler\n",
    "    geometric_mean = np.exp(np.log(markers_series).mean()) * scaler\n",
    "\n",
    "    print(\n",
    "        f\"\"\" {item} extrema:\n",
    "    {'Arithmetic mean' : <16}: {arithmetic_mean:8.2f}\n",
    "    {'Harmonic mean' : <16}: {harmonic_mean:8.2f}\n",
    "    {'Geometric mean' : <16}: {geometric_mean:8.2f}\n",
    "    {'Extrema' : <16}: {extrema_df[item].nlargest(3).to_list()}\n",
    "    \"\"\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('analytics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acbb1aea708f5888ce317e88d2db9ecb72c374939700585e6601647586e5137"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
